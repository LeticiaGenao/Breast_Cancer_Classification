# -*- coding: utf-8 -*-
"""Genao_ANA680_Week1_HW_RF

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1luMzsDGQW_rIecsbLntMaNdeJ6UyooM6

# **ANA 680 Week 1 Homework Assignment**
## Leticia Genao
## 05/09/24

### **Method: Random Forest**
"""

from google.colab import drive
drive.mount('/content/drive')

#Imports
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Read in file
path = '/content/drive/MyDrive/DS_Files/nu_python/ana_680/Breast_Cancer_Prediction.csv'
df=pd.read_csv(path)

"""# **Data Exploration**"""

# Show all the data
print("Basic DataFrame information:")
print(df.info())
print(df)

# Show the first five rows of the DataFrame
df.head()

"""#**Notes**
Sample code number appears to be an identifier
"""

# Show Summary statistics for the DataFrame
df.describe()

"""#**Notes**
*  ***Bare Nuclei***
  * Has a larger range and a higher standard deviation, suggesting substantial variability that may be important in determining the malignancy of a cancer. Given that the mean is greater than many other attributes, it is likely a shared characteristic of the samples offered.
*  ***Clump Thickness, Uniformity of Cell Size, and Uniformity of Cell Shape***
  * Compared to other parameters, such as mitoses, these features have larger averages, indicating variation in cell clumpiness and uniformity that may be directly related to the severity of the malignancy. Further investigation is needed.
"""

# Histograms for each feature
df.hist(bins=15, figsize=(15, 10), layout=(4, 3))
plt.suptitle('Histograms of each feature')
plt.show()

"""#**Notes**
*  ***Bi-modal Distributions***
  * Bi-modal distributions for "Clump Thickness" and "Uniformity of Cell Size" suggest that there may be two different groups in the sample, potentially reflecting benign and malignant tumors.
*  ***Skewed Distributions***
  * The feature "Mitoses" has a strong negative bias, indicating that high rates of mitosis are uncommon and, when they do occur, may be reliable markers of cancer.
"""

# Box plots to check for outliers
df.plot(kind='box', subplots=True, layout=(4, 3), sharex=False, sharey=False, figsize=(15, 10))
plt.suptitle('Box plots to check for outliers')
plt.show()

"""#**Notes**
*  ***Outliers***
  * There are a lot of outliers in several features. As previously indicated, 'Mitoses', for instance, exhibits a large number of values that are much above the primary data cluster and may be powerful indications of cancer.
*  ***Bare Nuclei and Bland Chromatin***
  * These features show samples with extreme values that may be important in differentiating between benign and malignant classes, as they have a large number of outliers over the upper quartile.
"""

# Correlation matrix heatmap
correlation_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.05)
plt.title('Correlation matrix of features')
plt.show()

"""#**Notes**
*  ***High Correlations***
  * 'Uniformity of Cell Size' and 'Uniformity of Cell Shape' are two of the highly correlated pairings (0.91). A high correlation between these traits and probable duplicate information shows that dimensionality reduction may be possible without a large loss of information.
*  ***Negative Correlations***
  * The majority of cellular properties either rise or decrease together, as evidenced by the very small number of measures that exhibit negative correlations and those that do not exhibit strong negative correlations.

# **Data Cleaning and Preprocessing**
"""

# Convert column names to snake_case for consistency and easier coding
df.columns = [col.strip().replace(' ', '_').lower() for col in df.columns]
print(df.columns)

# Convert 'Class' from 2,4 to 0,1
df['class'] = df['class'].replace({2: 0, 4: 1})
# Check
df.head()

# Prepare the data
X = df.drop(['class', 'sample_code_number'], axis=1) # Drop the target and non-predictive column
y = df['class'] # Target variable

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

"""# **Modeling & Evaluation**"""

# Initialize and fit Random Forest model
rf_model = RandomForestClassifier(n_estimators=10, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
rf_predictions = rf_model.predict(X_test)

# Evaluate the model
rf_accuracy = accuracy_score(y_test, rf_predictions)
rf_conf_matrix = confusion_matrix(y_test, rf_predictions)

# Print results
print(f"Accuracy: {rf_accuracy}")
print(f"Confusion Matrix:\n{rf_conf_matrix}")
print("Confusion Matrix:")
sns.heatmap(rf_conf_matrix, annot=True, fmt="d", cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix for Random Forest')
plt.show()